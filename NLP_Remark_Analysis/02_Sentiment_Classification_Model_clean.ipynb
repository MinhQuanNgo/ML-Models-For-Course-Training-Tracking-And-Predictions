{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ae3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede54d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d039516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55a79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5d70d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split (80-20):\n",
      "  Total records: 500\n",
      "  Training set: 400 (80.0%)\n",
      "  Test set: 100 (20.0%)\n",
      "\n",
      "Columns: ['Employee_ID', 'Associate_Name', 'Department', 'Evaluation_Result', 'Skill_Feedback_1', 'Skill_Feedback_2', 'Skill_Feedback_3', 'Overall_Feedback', 'Sentiment']\n",
      "\n",
      "Sentiment Distribution:\n",
      "Training set:\n",
      "  negative: 85 (21.2%)\n",
      "  neutral: 137 (34.2%)\n",
      "  positive: 178 (44.5%)\n",
      "Test set:\n",
      "  positive: 45 (45.0%)\n",
      "  neutral: 34 (34.0%)\n",
      "  negative: 21 (21.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_df = pd.read_csv('training_data_complete.csv')\n",
    "train_df, test_df = train_test_split(full_df, test_size=0.2, random_state=42, stratify=full_df['Sentiment'])\n",
    "\n",
    "print(\"Train-Test Split (80-20):\")\n",
    "print(f\"  Total records: {len(full_df)}\")\n",
    "print(f\"  Training set: {len(train_df)} ({len(train_df)/len(full_df):.1%})\")\n",
    "print(f\"  Test set: {len(test_df)} ({len(test_df)/len(full_df):.1%})\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(\"Training set:\")\n",
    "for sentiment in train_df['Sentiment'].unique():\n",
    "    count = (train_df['Sentiment'] == sentiment).sum()\n",
    "    pct = round(count / len(train_df) * 100, 1)\n",
    "    print(f\"  {sentiment}: {count} ({pct}%)\")\n",
    "print(\"Test set:\")\n",
    "for sentiment in test_df['Sentiment'].unique():\n",
    "    count = (test_df['Sentiment'] == sentiment).sum()\n",
    "    pct = round(count / len(test_df) * 100, 1)\n",
    "    print(f\"  {sentiment}: {count} ({pct}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971c42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete:\n",
      "  TF-IDF features: 498\n",
      "  Categorical features: 3\n",
      "  Total features: 501\n",
      "  Target classes: ['negative', 'neutral', 'positive']\n",
      "  Training samples: 400\n",
      "  Test samples: 100\n"
     ]
    }
   ],
   "source": [
    "train_df['combined_feedback'] = (train_df['Skill_Feedback_1'].fillna('') + ' ' + \n",
    "                                 train_df['Skill_Feedback_2'].fillna('') + ' ' + \n",
    "                                 train_df['Skill_Feedback_3'].fillna('') + ' ' + \n",
    "                                 train_df['Overall_Feedback'].fillna(''))\n",
    "\n",
    "test_df['combined_feedback'] = (test_df['Skill_Feedback_1'].fillna('') + ' ' + \n",
    "                                test_df['Skill_Feedback_2'].fillna('') + ' ' + \n",
    "                                test_df['Skill_Feedback_3'].fillna('') + ' ' + \n",
    "                                test_df['Overall_Feedback'].fillna(''))\n",
    "\n",
    "X_train_text = train_df['combined_feedback']\n",
    "X_train_cat = train_df[['Evaluation_Result']]\n",
    "y_train = train_df['Sentiment']\n",
    "\n",
    "X_test_text = test_df['combined_feedback']\n",
    "X_test_cat = test_df[['Evaluation_Result']]\n",
    "y_test = test_df['Sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=500, min_df=2, max_df=0.8, ngram_range=(1, 2), lowercase=True, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat, drop_first=False)\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat, drop_first=False)\n",
    "\n",
    "all_cols = set(X_train_cat_encoded.columns) | set(X_test_cat_encoded.columns)\n",
    "for col in all_cols:\n",
    "    if col not in X_train_cat_encoded.columns: X_train_cat_encoded[col] = 0\n",
    "    if col not in X_test_cat_encoded.columns: X_test_cat_encoded[col] = 0\n",
    "X_test_cat_encoded = X_test_cat_encoded[X_train_cat_encoded.columns]\n",
    "\n",
    "X_train_tfidf_dense = X_train_tfidf.toarray()\n",
    "X_test_tfidf_dense = X_test_tfidf.toarray()\n",
    "X_train_combined = np.hstack([X_train_tfidf_dense, X_train_cat_encoded.values])\n",
    "X_test_combined = np.hstack([X_test_tfidf_dense, X_test_cat_encoded.values])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "print(\"Feature Engineering Complete:\")\n",
    "print(f\"  TF-IDF features: {X_train_tfidf_dense.shape[1]}\")\n",
    "print(f\"  Categorical features: {X_train_cat_encoded.shape[1]}\")\n",
    "print(f\"  Total features: {X_train_combined.shape[1]}\")\n",
    "print(f\"  Target classes: {list(le.classes_)}\")\n",
    "print(f\"  Training samples: {X_train_combined.shape[0]}\")\n",
    "print(f\"  Test samples: {X_test_combined.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f8d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODELS WITH BALANCED CLASS WEIGHTS\n",
      "\n",
      "1. Logistic Regression... 1.0000\n",
      "2. Random Forest... 1.0000\n",
      "3. Gradient Boosting... 1.0000\n",
      "4. SVM... 1.0000\n",
      "\n",
      "MODEL PERFORMANCE SUMMARY:\n",
      "  Logistic Regression: 1.0000 (100/100)\n",
      "  Random Forest: 1.0000 (100/100)\n",
      "  Gradient Boosting: 1.0000 (100/100)\n",
      "  SVM: 1.0000 (100/100)\n",
      "\n",
      "BEST MODEL: Logistic Regression (1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING MODELS WITH BALANCED CLASS WEIGHTS\\n\")\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "print(\"1. Logistic Regression...\", end=\" \")\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "lr.fit(X_train_combined, y_train_encoded)\n",
    "y_pred_lr = lr.predict(X_test_combined)\n",
    "acc_lr = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "results['Logistic Regression'] = {'accuracy': acc_lr, 'predictions': y_pred_lr}\n",
    "models['Logistic Regression'] = lr\n",
    "print(f\"{acc_lr:.4f}\")\n",
    "\n",
    "print(\"2. Random Forest...\", end=\" \")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "rf.fit(X_train_combined, y_train_encoded)\n",
    "y_pred_rf = rf.predict(X_test_combined)\n",
    "acc_rf = accuracy_score(y_test_encoded, y_pred_rf)\n",
    "results['Random Forest'] = {'accuracy': acc_rf, 'predictions': y_pred_rf}\n",
    "models['Random Forest'] = rf\n",
    "print(f\"{acc_rf:.4f}\")\n",
    "\n",
    "print(\"3. Gradient Boosting...\", end=\" \")\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1)\n",
    "gb.fit(X_train_combined, y_train_encoded)\n",
    "y_pred_gb = gb.predict(X_test_combined)\n",
    "acc_gb = accuracy_score(y_test_encoded, y_pred_gb)\n",
    "results['Gradient Boosting'] = {'accuracy': acc_gb, 'predictions': y_pred_gb}\n",
    "models['Gradient Boosting'] = gb\n",
    "print(f\"{acc_gb:.4f}\")\n",
    "\n",
    "print(\"4. SVM...\", end=\" \")\n",
    "svm = SVC(kernel='rbf', random_state=42, probability=True, class_weight='balanced')\n",
    "svm.fit(X_train_combined, y_train_encoded)\n",
    "y_pred_svm = svm.predict(X_test_combined)\n",
    "acc_svm = accuracy_score(y_test_encoded, y_pred_svm)\n",
    "results['SVM'] = {'accuracy': acc_svm, 'predictions': y_pred_svm}\n",
    "models['SVM'] = svm\n",
    "print(f\"{acc_svm:.4f}\")\n",
    "\n",
    "print(\"\\nMODEL PERFORMANCE SUMMARY:\")\n",
    "for model_name in sorted(results.keys(), key=lambda x: results[x]['accuracy'], reverse=True):\n",
    "    acc = results[model_name]['accuracy']\n",
    "    print(f\"  {model_name}: {acc:.4f} ({int(acc*len(y_test_encoded))}/{len(y_test_encoded)})\")\n",
    "\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "best_model = models[best_model_name]\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "print(f\"\\nBEST MODEL: {best_model_name} ({results[best_model_name]['accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d83817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentPredictor initialized\n",
      "Model: Logistic Regression\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "class SentimentPredictor:\n",
    "    def __init__(self, model, tfidf_vectorizer, label_encoder, cat_encoder_cols):\n",
    "        self.model = model\n",
    "        self.tfidf = tfidf_vectorizer\n",
    "        self.le = label_encoder\n",
    "        self.cat_cols = cat_encoder_cols\n",
    "        \n",
    "    def _prepare_features(self, skill_fb1, skill_fb2, skill_fb3, overall_fb, eval_result):\n",
    "        combined_text = f\"{skill_fb1} {skill_fb2} {skill_fb3} {overall_fb}\"\n",
    "        X_tfidf = self.tfidf.transform(pd.Series([combined_text])).toarray()\n",
    "        \n",
    "        X_cat = pd.DataFrame({'Evaluation_Result': [eval_result]})\n",
    "        X_cat_encoded = pd.get_dummies(X_cat, drop_first=False)\n",
    "        \n",
    "        for col in self.cat_cols:\n",
    "            if col not in X_cat_encoded.columns:\n",
    "                X_cat_encoded[col] = 0\n",
    "        X_cat_encoded = X_cat_encoded[self.cat_cols]\n",
    "        \n",
    "        X_combined = np.hstack([X_tfidf, X_cat_encoded.values])\n",
    "        return X_combined\n",
    "    \n",
    "    def predict_single(self, skill_feedback_1, skill_feedback_2, skill_feedback_3, \n",
    "                      overall_feedback, evaluation_result):\n",
    "        X = self._prepare_features(skill_feedback_1, skill_feedback_2, skill_feedback_3,\n",
    "                                   overall_feedback, evaluation_result)\n",
    "        pred_encoded = self.model.predict(X)[0]\n",
    "        sentiment = self.le.inverse_transform([pred_encoded])[0]\n",
    "        return sentiment\n",
    "    \n",
    "    def predict_batch(self, dataframe, skill_fb1_col='Skill_Feedback_1', \n",
    "                     skill_fb2_col='Skill_Feedback_2', skill_fb3_col='Skill_Feedback_3',\n",
    "                     overall_fb_col='Overall_Feedback', eval_result_col='Evaluation_Result'):\n",
    "        predictions = []\n",
    "        for idx, row in dataframe.iterrows():\n",
    "            pred = self.predict_single(\n",
    "                row[skill_fb1_col],\n",
    "                row[skill_fb2_col],\n",
    "                row[skill_fb3_col],\n",
    "                row[overall_fb_col],\n",
    "                row[eval_result_col]\n",
    "            )\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        result_df = dataframe.copy()\n",
    "        result_df['Predicted_Sentiment'] = predictions\n",
    "        return result_df\n",
    "    \n",
    "    def predict_from_json(self, filepath, output_filepath=None):\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            data = [data]\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        predictions_df = self.predict_batch(df)\n",
    "        \n",
    "        if output_filepath:\n",
    "            predictions_df.to_csv(output_filepath, index=False)\n",
    "            print(f\"Predictions saved: {output_filepath}\")\n",
    "        \n",
    "        return predictions_df\n",
    "\n",
    "predictor = SentimentPredictor(\n",
    "    model=best_model,\n",
    "    tfidf_vectorizer=tfidf,\n",
    "    label_encoder=le,\n",
    "    cat_encoder_cols=list(X_train_cat_encoded.columns)\n",
    ")\n",
    "\n",
    "print(\"SentimentPredictor initialized\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {results[best_model_name]['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9409d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED TEST SET PREDICTIONS & EVALUATION\n",
      "\n",
      "OVERALL ACCURACY: 100.00% (100/100)\n",
      "\n",
      "ACCURACY BY SENTIMENT CLASS:\n",
      "  NEGATIVE: 21/21 (100.00%)\n",
      "  NEUTRAL: 34/34 (100.00%)\n",
      "  POSITIVE: 45/45 (100.00%)\n",
      "\n",
      "Predictions saved: model_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"DETAILED TEST SET PREDICTIONS & EVALUATION\\n\")\n",
    "\n",
    "predictions_df = test_df.copy()\n",
    "predictions_df['Predicted_Sentiment'] = le.inverse_transform(best_predictions)\n",
    "predictions_df['True_Sentiment'] = y_test\n",
    "predictions_df['Correct'] = predictions_df['Predicted_Sentiment'] == predictions_df['True_Sentiment']\n",
    "\n",
    "total_correct = predictions_df['Correct'].sum()\n",
    "total_records = len(predictions_df)\n",
    "overall_accuracy = total_correct / total_records\n",
    "print(f\"OVERALL ACCURACY: {overall_accuracy:.2%} ({total_correct}/{total_records})\\n\")\n",
    "\n",
    "print(\"ACCURACY BY SENTIMENT CLASS:\")\n",
    "for sentiment in le.classes_:\n",
    "    mask = predictions_df['True_Sentiment'] == sentiment\n",
    "    total = mask.sum()\n",
    "    correct = (predictions_df[mask]['Correct']).sum()\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    print(f\"  {sentiment.upper()}: {correct}/{total} ({acc:.2%})\")\n",
    "\n",
    "predictions_df.to_csv('model_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved: model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22083ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING FINAL FEEDBACK BASED ON PREDICTED SENTIMENTS\n",
      "\n",
      "Sample Final Feedbacks:\n",
      "\n",
      "1. Rohan Chopra (positive): Ready for advancement. Demonstrates strong capabilities and readiness for growth.\n",
      "2. Kavya Reddy (neutral): Conditional progression. Shows promise but requires targeted development in identified areas.\n",
      "3. Kavya Desai (positive): Ready for advancement. Demonstrates strong capabilities and readiness for growth.\n",
      "4. Shreya Sharma (negative): Requires improvement. Needs additional support and training with mentorship.\n",
      "5. Shreya Singh (negative): Requires improvement. Needs additional support and training with mentorship.\n",
      "\n",
      "Final CSV saved: final_feedback_with_all_columns.csv\n",
      "Total records: 100\n",
      "Columns: ['Employee_ID', 'Associate_Name', 'Department', 'Evaluation_Result', 'Skill_Feedback_1', 'Skill_Feedback_2', 'Skill_Feedback_3', 'Overall_Feedback', 'Sentiment', 'Predicted_Sentiment', 'Final_Feedback']\n"
     ]
    }
   ],
   "source": [
    "print(\"GENERATING FINAL FEEDBACK BASED ON PREDICTED SENTIMENTS\\n\")\n",
    "\n",
    "def generate_concise_feedback(predicted_sentiment):\n",
    "    if predicted_sentiment == 'positive':\n",
    "        return \"Ready for advancement. Demonstrates strong capabilities and readiness for growth.\"\n",
    "    elif predicted_sentiment == 'neutral':\n",
    "        return \"Conditional progression. Shows promise but requires targeted development in identified areas.\"\n",
    "    else:\n",
    "        return \"Requires improvement. Needs additional support and training with mentorship.\"\n",
    "\n",
    "predictions_df = test_df.copy()\n",
    "predictions_df['Predicted_Sentiment'] = le.inverse_transform(best_predictions)\n",
    "predictions_df['Final_Feedback'] = predictions_df['Predicted_Sentiment'].apply(generate_concise_feedback)\n",
    "\n",
    "print(\"Sample Final Feedbacks:\\n\")\n",
    "for idx in range(5):\n",
    "    print(f\"{idx+1}. {predictions_df['Associate_Name'].iloc[idx]} ({predictions_df['Predicted_Sentiment'].iloc[idx]}): {predictions_df['Final_Feedback'].iloc[idx]}\")\n",
    "\n",
    "final_df = predictions_df[[\n",
    "    'Employee_ID', 'Associate_Name', 'Department', 'Evaluation_Result',\n",
    "    'Skill_Feedback_1', 'Skill_Feedback_2', 'Skill_Feedback_3', 'Overall_Feedback',\n",
    "    'Sentiment', 'Predicted_Sentiment', 'Final_Feedback'\n",
    "]]\n",
    "\n",
    "final_df.to_csv('final_feedback_with_all_columns.csv', index=False)\n",
    "print(f\"\\nFinal CSV saved: final_feedback_with_all_columns.csv\")\n",
    "print(f\"Total records: {len(final_df)}\")\n",
    "print(f\"Columns: {list(final_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c57310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d7b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
